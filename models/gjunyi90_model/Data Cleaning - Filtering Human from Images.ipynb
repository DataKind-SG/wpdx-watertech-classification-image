{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Human Detection Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from imageai.Detection import ObjectDetection\n",
    "import os\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option('display.max_rows', 10)\n",
    "pd.set_option('display.max_columns', 10)\n",
    "pd.set_option('display.max_colwidth', 500)\n",
    "\n",
    "def get_human_ratio(image, detector):\n",
    "    human_ratios = []\n",
    "\n",
    "    im = Image.open(image)\n",
    "    image_size = im.size[0] * im.size[1]\n",
    "\n",
    "    detections = detector.detectObjectsFromImage(input_image=image)\n",
    "    for detection in detections:\n",
    "        for i, attribute in enumerate(detection.values()):\n",
    "            if attribute == 'person':\n",
    "                human_box = list(detection.values())[2]\n",
    "\n",
    "                # Box Points - [x1,y1,x2,y2]\n",
    "                human_size = (human_box[2] - human_box[0]) * (human_box[3] - human_box[1])\n",
    "                human_ratios.append(human_size / image_size)\n",
    "    return human_ratios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading of Object Detection Model\n",
    "\n",
    "In order to start detecting the human in the images, we need to have a trained model for this. The trained model can be downloaded from the following link:\n",
    "https://github.com/OlafenwaMoses/ImageAI/releases/download/1.0/resnet50_coco_best_v2.0.1.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "execution_path = os.getcwd()\n",
    "detector = ObjectDetection()\n",
    "detector.setModelTypeAsRetinaNet()\n",
    "detector.setModelPath(os.path.join(execution_path, \"resnet50_coco_best_v2.0.1.h5\"))\n",
    "detector.loadModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detect humans in all images\n",
    "The list detection_list will save all the images' path and also the percentage of humans detection in each image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'data/images'\n",
    "data_path_full = (Path().resolve().parents[1] / f'{data_path}').resolve()\n",
    "folders = data_path_full.glob(\"*/*\")\n",
    "detection_list = []\n",
    "\n",
    "for folder in folders:\n",
    "    files = folder.resolve().glob(\"*.*\")\n",
    "    for file in list(files):\n",
    "        ratio = sum(get_human_ratio(file, detector))\n",
    "        detection_list.append([str(file), ratio])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving and loading list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"detection_list.pkl\", \"wb\") as f:\n",
    "    pickle.dump(detection_list, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"detection_list.pkl\", \"rb\") as fp:   # Unpickling\n",
    "    detection_list2 = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding the image composition\n",
    "Training a good model requires sufficient training data and also clean data. In this section, we aim to strike a balance between this the quantity and the quality of images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "    \n",
    "filtered_samples = pd.DataFrame(detection_list2, columns=[\"File\", \"Detection_Pct\"])\n",
    "\n",
    "def replace_folder(str_list, dest = 'filtered'):\n",
    "    # Remove train/val/test folder\n",
    "    del str_list[-3]\n",
    "    str_list[-3] = dest\n",
    "    new_path = '\\\\'.join(str_list)\n",
    "    return new_path\n",
    "\n",
    "filtered_samples['NewPath'] = filtered_samples.File.str.split('\\\\').apply(replace_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['File', 'Detection_Pct', 'NewPath', 'Category'], dtype='object')"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_samples.loc[:,'Category'] = filtered_samples.File.apply(lambda x: x.split('\\\\')[-2])\n",
    "filtered_samples.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of images per Class at each Detection_Pct Bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Category</th>\n",
       "      <th>Borehole - Mechanized</th>\n",
       "      <th>Borehole - Mechanized with diesel</th>\n",
       "      <th>Bucket</th>\n",
       "      <th>Hand Pump</th>\n",
       "      <th>Hand Pump - Afridev</th>\n",
       "      <th>Hand Pump - India Mark II</th>\n",
       "      <th>Hand Pump - Vergnet</th>\n",
       "      <th>Kiosk</th>\n",
       "      <th>Other</th>\n",
       "      <th>Protected Spring</th>\n",
       "      <th>Tapstand</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bin</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>(-0.101, 0.0]</th>\n",
       "      <td>63.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>624.0</td>\n",
       "      <td>686.0</td>\n",
       "      <td>677.0</td>\n",
       "      <td>674.0</td>\n",
       "      <td>624.0</td>\n",
       "      <td>845.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>236.0</td>\n",
       "      <td>874.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.0, 0.05]</th>\n",
       "      <td>68.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>675.0</td>\n",
       "      <td>750.0</td>\n",
       "      <td>760.0</td>\n",
       "      <td>737.0</td>\n",
       "      <td>693.0</td>\n",
       "      <td>877.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>917.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.05, 0.1]</th>\n",
       "      <td>72.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>725.0</td>\n",
       "      <td>795.0</td>\n",
       "      <td>791.0</td>\n",
       "      <td>786.0</td>\n",
       "      <td>761.0</td>\n",
       "      <td>907.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>268.0</td>\n",
       "      <td>940.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.1, 0.15]</th>\n",
       "      <td>75.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>791.0</td>\n",
       "      <td>830.0</td>\n",
       "      <td>851.0</td>\n",
       "      <td>833.0</td>\n",
       "      <td>820.0</td>\n",
       "      <td>930.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>278.0</td>\n",
       "      <td>952.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.15, 0.2]</th>\n",
       "      <td>76.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>847.0</td>\n",
       "      <td>866.0</td>\n",
       "      <td>887.0</td>\n",
       "      <td>873.0</td>\n",
       "      <td>862.0</td>\n",
       "      <td>947.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>284.0</td>\n",
       "      <td>958.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.2, 0.3]</th>\n",
       "      <td>78.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>930.0</td>\n",
       "      <td>927.0</td>\n",
       "      <td>939.0</td>\n",
       "      <td>935.0</td>\n",
       "      <td>927.0</td>\n",
       "      <td>963.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>304.0</td>\n",
       "      <td>974.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.3, 0.4]</th>\n",
       "      <td>80.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>974.0</td>\n",
       "      <td>957.0</td>\n",
       "      <td>970.0</td>\n",
       "      <td>972.0</td>\n",
       "      <td>960.0</td>\n",
       "      <td>977.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>314.0</td>\n",
       "      <td>983.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.4, 0.5]</th>\n",
       "      <td>81.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>986.0</td>\n",
       "      <td>977.0</td>\n",
       "      <td>987.0</td>\n",
       "      <td>988.0</td>\n",
       "      <td>976.0</td>\n",
       "      <td>985.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>318.0</td>\n",
       "      <td>992.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.5, 1.0]</th>\n",
       "      <td>82.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>997.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>998.0</td>\n",
       "      <td>999.0</td>\n",
       "      <td>999.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>324.0</td>\n",
       "      <td>999.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Category       Borehole - Mechanized  Borehole - Mechanized with diesel  \\\n",
       "Bin                                                                       \n",
       "(-0.101, 0.0]                   63.0                                3.0   \n",
       "(0.0, 0.05]                     68.0                                5.0   \n",
       "(0.05, 0.1]                     72.0                                5.0   \n",
       "(0.1, 0.15]                     75.0                                5.0   \n",
       "(0.15, 0.2]                     76.0                                5.0   \n",
       "(0.2, 0.3]                      78.0                                6.0   \n",
       "(0.3, 0.4]                      80.0                                6.0   \n",
       "(0.4, 0.5]                      81.0                                6.0   \n",
       "(0.5, 1.0]                      82.0                                6.0   \n",
       "\n",
       "Category       Bucket  Hand Pump  Hand Pump - Afridev  \\\n",
       "Bin                                                     \n",
       "(-0.101, 0.0]   624.0      686.0                677.0   \n",
       "(0.0, 0.05]     675.0      750.0                760.0   \n",
       "(0.05, 0.1]     725.0      795.0                791.0   \n",
       "(0.1, 0.15]     791.0      830.0                851.0   \n",
       "(0.15, 0.2]     847.0      866.0                887.0   \n",
       "(0.2, 0.3]      930.0      927.0                939.0   \n",
       "(0.3, 0.4]      974.0      957.0                970.0   \n",
       "(0.4, 0.5]      986.0      977.0                987.0   \n",
       "(0.5, 1.0]     1000.0      997.0               1000.0   \n",
       "\n",
       "Category       Hand Pump - India Mark II  Hand Pump - Vergnet  Kiosk  Other  \\\n",
       "Bin                                                                           \n",
       "(-0.101, 0.0]                      674.0                624.0  845.0    6.0   \n",
       "(0.0, 0.05]                        737.0                693.0  877.0    6.0   \n",
       "(0.05, 0.1]                        786.0                761.0  907.0    6.0   \n",
       "(0.1, 0.15]                        833.0                820.0  930.0    6.0   \n",
       "(0.15, 0.2]                        873.0                862.0  947.0    8.0   \n",
       "(0.2, 0.3]                         935.0                927.0  963.0    8.0   \n",
       "(0.3, 0.4]                         972.0                960.0  977.0   10.0   \n",
       "(0.4, 0.5]                         988.0                976.0  985.0   10.0   \n",
       "(0.5, 1.0]                         998.0                999.0  999.0   10.0   \n",
       "\n",
       "Category       Protected Spring  Tapstand  \n",
       "Bin                                        \n",
       "(-0.101, 0.0]             236.0     874.0  \n",
       "(0.0, 0.05]               250.0     917.0  \n",
       "(0.05, 0.1]               268.0     940.0  \n",
       "(0.1, 0.15]               278.0     952.0  \n",
       "(0.15, 0.2]               284.0     958.0  \n",
       "(0.2, 0.3]                304.0     974.0  \n",
       "(0.3, 0.4]                314.0     983.0  \n",
       "(0.4, 0.5]                318.0     992.0  \n",
       "(0.5, 1.0]                324.0     999.0  "
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "bins = [-0.1,0,0.05,0.1,0.15,0.2,0.3,0.4,0.5,1]\n",
    "\n",
    "filtered_samples['Bin'] = pd.cut(filtered_samples.Detection_Pct,bins=bins, include_lowest=True)\n",
    "filtered_samples.head()\n",
    "summary_pivot = filtered_samples.drop(columns=['File','NewPath']).pivot_table(index='Bin', columns='Category',aggfunc=['count']).fillna(0)\n",
    "summary_pivot.sort_values(by=['Bin'], ascending=True).astype('float').cumsum().droplevel(axis='columns', level=[0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Removal Decision\n",
    "It can be observed from the table that categories with low number of data such as \"Borehole - Mechanized with diesel\" and \"Other\" have only up to 40% of the image that is occupied by humans.\n",
    "\n",
    "By removing the images that have more than __40% of human detected__, we can prevent removing any images from these two categories. Furthermore, it will retent sufficient training images for the other categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_samples = filtered_samples[filtered_samples.Detection_Pct < 0.4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Putting the images into a new folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import shutil\n",
    "\n",
    "proc_folder = 'filtered'\n",
    "data_path = Path('\\\\'.join(filtered_samples.iloc[0][2].split('\\\\')[:-3])).resolve()\n",
    "\n",
    "for index, rows in filtered_samples.iterrows():\n",
    "    files = rows['File'].split('\\\\')\n",
    "    if (data_path/proc_folder).is_dir()==False:\n",
    "        pathlib.Path.mkdir(data_path/proc_folder)\n",
    "    if (data_path/proc_folder/files[-2]).is_dir()==False:\n",
    "        pathlib.Path.mkdir(data_path/proc_folder/files[-2])\n",
    "    shutil.copy((rows['File']), (rows['NewPath']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train / Val / Test Split\n",
    "Using this repository split_folders, we can easily split the images into train/val/test dataset for keras model training.\n",
    "\n",
    "This library can be installed using the following command:\n",
    "```\n",
    "pip install split-folders\n",
    "```\n",
    "Detailed documentation can be found in the github repository:\n",
    "https://github.com/jfilter/split-folders\n",
    "\n",
    "I chose to split the dataset into 65% training data so that there will be sufficient validation data and also not too little testing data because of the lack of images in the \"Borehole - Mechanized with diesel\" and \"Other\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying files: 7203 files [00:14, 499.12 files/s]\n"
     ]
    }
   ],
   "source": [
    "import split_folders\n",
    "\n",
    "split_folders.ratio('../../data/filtered', output=\"../../data/filtered_split\", seed=1337, ratio=(.65, .15, .2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
