{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation\n",
    "One way of feeding the image data into Keras is by organizing the train/val/test dataset in the following directory structure.\n",
    "\n",
    "```\n",
    "images \n",
    "└───train\n",
    "│   └───class_1\n",
    "│       │   image001.jpg\n",
    "│       │   image002.jpg\n",
    "│       │   ...\n",
    "│   └───class_2\n",
    "└───val\n",
    "│   └───class_1\n",
    "│       │   ...\n",
    "└───test\n",
    "│   └───class_1\n",
    "│       │   ...\n",
    "```\n",
    "We can use this library __split_folders__ to split our original dataset into train/val/test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import split_folders\n",
    "\n",
    "split_folders.ratio('../../data/images/train', output=\"../../data/images/new\", seed=1337, ratio=(.8, .2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Corrupted exif tags in Images\n",
    "It was observed that several warnings were shown during Keras model training. This was resulted by some corrupted exif tags on the jpeg images. In order to ensure that the corrupted images are not affecting the training process, we can perform a simple fix to this by removing all the exif tags in all the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import piexif\n",
    "\n",
    "for folder in folders_list:\n",
    "    folder_path = pathlib.Path(folder).resolve()\n",
    "    files = folder_path.glob('*.*')\n",
    "    for file in files:\n",
    "        piexif.remove(str(file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imbalanced classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Borehole - Mechanized': 52,\n",
       " 'Borehole - Mechanized with diesel': 4,\n",
       " 'Bucket': 640,\n",
       " 'Hand Pump': 640,\n",
       " 'Hand Pump - Afridev': 640,\n",
       " 'Hand Pump - India Mark II': 640,\n",
       " 'Hand Pump - Vergnet': 640,\n",
       " 'Kiosk': 640,\n",
       " 'Other': 6,\n",
       " 'Protected Spring': 207,\n",
       " 'Tapstand': 640}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pathlib\n",
    "from pprint import pprint\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "train_images_path = '../../data/images/train'\n",
    "path = pathlib.Path(train_images_path).resolve()\n",
    "folders = path.glob(\"*/\")\n",
    "folders_list = [folder.resolve() for folder in folders]\n",
    "\n",
    "files_count = {folder.name: len(list(folder.glob(\"*.*\"))) for i, folder in enumerate(folders_list)}\n",
    "files_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two classes have extremely low number of training data and would likely result in a model that can not classify these two classes properly.\n",
    "- Borehole - Mechanized with diesel\n",
    "- Other\n",
    "\n",
    "However, I would like to keep the 11 classes first as a preliminary model and evaluate if it gives undesirable results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class weights\n",
    "In order to prevent a biased model which will always predict the class with more data. One way of fixing the imbalance class issue in a classification problem is that we can force our algorithm to treat every instance of \"class 1\" as 50 instances of \"class 0\". This is done by implementing class weights.\n",
    "\n",
    "The class weights in keras is in dictionary format:\n",
    "```\n",
    "{0.0: <class_weight0>, 1.0: <class_weight1>, 2.0: <class_weight2>, ...}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.0: 12.307692307692308,\n",
       " 1.0: 160.0,\n",
       " 2.0: 1.0,\n",
       " 3.0: 1.0,\n",
       " 4.0: 1.0,\n",
       " 5.0: 1.0,\n",
       " 6.0: 1.0,\n",
       " 7.0: 1.0,\n",
       " 8.0: 106.66666666666667,\n",
       " 9.0: 3.0917874396135265,\n",
       " 10.0: 1.0}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_count = {float(i): len(list(folder.glob(\"*.*\"))) for i, folder in enumerate(folders_list)}\n",
    "class_weight = {key: max(class_count.values())/class_count[key] for key in iter(class_count)}\n",
    "class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from keras.applications import MobileNet\n",
    "from keras.applications.mobilenet import preprocess_input\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Model, load_model\n",
    "from keras.optimizers import Adam\n",
    "from keras_tqdm import TQDMNotebookCallback\n",
    "\n",
    "base_model = MobileNet(weights='imagenet',\n",
    "                       include_top=False)  # imports the mobilenet model and discards the last 1000 neuron layer.\n",
    "\n",
    "dropout_rate = 0.35\n",
    "\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)  # we add dense layers so that the model can learn more complex functions and classify for better results.\n",
    "x = Dropout(dropout_rate)(x)\n",
    "x = Dense(1024, activation='relu')(x)  # dense layer 2\n",
    "x = Dropout(dropout_rate)(x)\n",
    "x = Dense(512, activation='relu')(x)  # dense layer 3\n",
    "preds = Dense(11, activation='softmax')(x)  # final layer with softmax activation\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=preds)\n",
    "\n",
    "for layer in model.layers[:20]:\n",
    "    layer.trainable = False\n",
    "for layer in model.layers[20:]:\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Borehole - Mechanized',\n",
       " 'Borehole - Mechanized with diesel',\n",
       " 'Bucket',\n",
       " 'Hand Pump',\n",
       " 'Hand Pump - Afridev',\n",
       " 'Hand Pump - India Mark II',\n",
       " 'Hand Pump - Vergnet',\n",
       " 'Kiosk',\n",
       " 'Other',\n",
       " 'Protected Spring',\n",
       " 'Tapstand']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = [folder.name for folder in folders_list]\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect specific layers\n",
    "# for layer in model.layers[-4:]:\n",
    "#     pprint(layer.get_config())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4749 images belonging to 11 classes.\n",
      "Found 1189 images belonging to 11 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                    shear_range=0.2,\n",
    "                                    zoom_range=0.2,\n",
    "                                    horizontal_flip=True)  # included in our dependencies\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory('../../data/images/train',\n",
    "                                                    target_size=(224, 224),\n",
    "                                                    color_mode='rgb',\n",
    "                                                    batch_size=64,\n",
    "                                                    classes=classes,\n",
    "                                                    class_mode='categorical',\n",
    "                                                    shuffle=True)\n",
    "\n",
    "valid_generator = train_datagen.flow_from_directory('../../data/images/val',\n",
    "                                                    target_size=(224, 224),\n",
    "                                                    color_mode='rgb',\n",
    "                                                    batch_size=64,\n",
    "                                                    classes=classes,\n",
    "                                                    class_mode='categorical',\n",
    "                                                    shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Rate Scheduler\n",
    "https://machinelearningmastery.com/using-learning-rate-schedules-deep-learning-models-python-keras/\n",
    "\n",
    "In this model training process, learning rate will decay based on the epochs of the training process (i.e. Step Decay). This learning rate refinement will facilitate the convergance of models accuracy automatically instead of manually adjusting the learning rate manually.\n",
    "\n",
    "When LearningRateScheduler is used, the learning rate specified by Adam is ignored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_lrate = 0.000\n",
    "epoch = 10\n",
    "drop = 0.1\n",
    "epochs_drop = 5.0\n",
    "lrate = initial_lrate * math.pow(drop, math.floor((epoch)/epochs_drop))\n",
    "float(lrate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import LearningRateScheduler, ModelCheckpoint, EarlyStopping\n",
    "import math\n",
    "\n",
    "# learning rate schedule\n",
    "def step_decay(epoch):\n",
    "    initial_lrate = 0.0005\n",
    "    drop = 0.5\n",
    "    epochs_drop = 5.0\n",
    "    lrate = initial_lrate * math.pow(drop, math.floor((1+epoch)/epochs_drop))\n",
    "    return lrate\n",
    "\n",
    "# learning schedule callback\n",
    "lrate = LearningRateScheduler(step_decay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Early Stopping\n",
    "https://machinelearningmastery.com/how-to-stop-training-deep-neural-networks-at-the-right-time-using-early-stopping/\n",
    "Since "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple early stopping\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Checkpoint\n",
    "https://machinelearningmastery.com/how-to-stop-training-deep-neural-networks-at-the-right-time-using-early-stopping/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc = ModelCheckpoint('best_model.h5', monitor='val_acc', mode='max', verbose=1, save_best_only=True)\n",
    "callbacks_list = [lrate,es,mc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "step_size_train = train_generator.n // train_generator.batch_size\n",
    "step_size_valid = valid_generator.n // valid_generator.batch_size\n",
    "model.fit_generator(generator=train_generator, validation_data=valid_generator, steps_per_epoch=step_size_train, validation_steps=step_size_valid, epochs=200, class_weight=class_weight, \n",
    "                    verbose=2, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the Model and the Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# save:\n",
    "f = open('history.pckl', 'wb')\n",
    "pickle.dump(model.history, f)\n",
    "f.close()\n",
    "\n",
    "# retrieve:\n",
    "f = open('history.pckl', 'rb')\n",
    "history = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model and architecture to single file\n",
    "model.save(\"model_oversample3.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Process Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "# history = model.fit(x, y, validation_split=0.25, epochs=50, batch_size=16, verbose=1)\n",
    "\n",
    "# retrieve:\n",
    "f = open('history.pckl', 'rb')\n",
    "history = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "# Plot training & validation accuracy values\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1484 images belonging to 11 classes.\n",
      "[0.7527404284995535, 0.7778532608695652]\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# model.save('my_model.h5')  # creates a HDF5 file 'my_model.h5'\n",
    "# del model  # deletes the existing model\n",
    "\n",
    "# returns a compiled model\n",
    "# identical to the previous one\n",
    "model = load_model('best_model.h5')\n",
    "\n",
    "# STEP_SIZE_TEST=test_generator.n//test_generator.batch_size\n",
    "# test_generator.reset()\n",
    "# pred=model.predict_generator(test_generator,\n",
    "# steps=STEP_SIZE_TEST,\n",
    "# verbose=1)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_generator = test_datagen.flow_from_directory('../../data/images/test',\n",
    "                                                    target_size=(224, 224),\n",
    "                                                    color_mode='rgb',\n",
    "                                                    batch_size=64,\n",
    "                                                    classes=classes,\n",
    "                                                    class_mode='categorical')\n",
    "step_size_test = test_generator.n // test_generator.batch_size\n",
    "\n",
    "loss_and_metrics = model.evaluate_generator(test_generator, steps=step_size_test)\n",
    "print(loss_and_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
